Fill in your answers here.

1. It identifies the sticky note well; however, it mistakenly identifies the surrounding of the sticky note and the upper right corner of the sky as "close by" as well. The surrounding of the sticky note is marked because from the right picture it is covered by the sticky note and there is no other place with the same gray shaded colors; therefore, the algorithm looks for the search space and finds ones that are of the similar colors. And for the sky, because it is basically all white with the same value, if there is any gray dot(s) among the sky the algorithm will be too accurate and mess the output up.

2. The algorithm works better on real2 images. It also has the problem of identifying the region covered by the sticky note as "close by" when looking through the right camera. However, this time there is no mistakenly identified floating region like the sky in real1 images, because the region the algorithm goes over does not consist of just one single plain color like the white sky in real1 images but consist of more distinct background, which is easier to deal with.

3. The edges of the images become gray and as the feature heights and widths increase, the gray edges become thicker. This is due to the fact that we assign the given pixel distance value of 0 (infinity) when its feature extends beyond the image as the dimension increases. Besides, the characters become fuzzier as the dimension increases because the feature space is larger; therefore, the euclidean distances of each pixel within the search space are more similar and therefore would make the characters more vague as feature widths and heights increase.